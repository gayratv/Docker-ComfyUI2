# bytedance-research/UNO
# dit_lora.safetensors
https://huggingface.co/bytedance-research/UNO/resolve/main/dit_lora.safetensors
    out=dit_lora.safetensors
    dir=models/loras/uno_lora

## ðŸŒŸ https://huggingface.co/Kijai/flux-fp8 ðŸŒŸ
## flux1-dev-fp8-e4m3fn.safetensors
##https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8-e4m3fn.safetensors
#  dir=models/unet
#  out=flux-dev-fp8.safetensors
#
##  ðŸŒŸ CLIP ðŸŒŸ
## comfyanonymous/flux_text_encoders
#https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors
#    out=clip_l.safetensors
#    dir=models/clip
#
## comfyanonymous/flux_text_encoders
#https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors
#    out=t5xxl_fp16.safetensors
#    dir=models/clip
#
#https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus/resolve/main/image_encoder/pytorch_model.bin
#    dir=models/clip_vision
#    out=clip-vit-large-patch14-336.bin